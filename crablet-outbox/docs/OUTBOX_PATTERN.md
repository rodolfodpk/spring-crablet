# Outbox Pattern for DCB Event Sourcing

## Quick Reference

**Outbox pattern in 60 seconds:**

The outbox provides **reliable event publishing** for DCB-based event sourcing. It ensures events are published to external systems (Kafka, webhooks, analytics) with the same transactional guarantees as your DCB operations.

**How it works:**
1. Handler returns `CommandResult(events, condition)`
2. `CommandExecutor` calls `EventStore.appendIf()` â†’ stores events in `events` table
3. Outbox processor polls `events` table (`WHERE position > last_position`)
4. Publishers send events to external systems
5. Progress tracking updates `outbox_topic_progress` with new position

**Key Features:**
- âœ… At-least-once delivery semantics
- âœ… Leader election for high availability (2 instances recommended)
- âœ… Per-publisher progress tracking
- âœ… Automatic failover (5-30 seconds)

ğŸ“– **Details:** See [sections below](#dcb-integration).

## Overview

The outbox pattern provides **reliable event publishing** for DCB-based event sourcing. It ensures events are published to external systems (Kafka, webhooks, analytics) with the same transactional guarantees as your DCB operations.

## DCB Integration

### How It Works with DCB

```java
public CommandResult handleTransfer(TransferCommand command) {
    // 1. DCB: Read current state with cursor
    ProjectionResult<WalletBalanceState> projection = 
        balanceProjector.projectWalletBalance(eventStore, command.fromWalletId(), decisionModel);
    
    // 2. Business logic - generate multiple events
    MoneyTransferred transfer = MoneyTransferred.of(/* ... */);
    DepositMade deposit = DepositMade.of(/* ... */);
    WithdrawalMade withdrawal = WithdrawalMade.of(/* ... */);
    
    // 3. DCB: Append multiple events with concurrency control
    List<AppendEvent> events = List.of(
        AppendEvent.builder("MoneyTransferred")
            .tag("from_wallet_id", command.fromWalletId())
            .tag("to_wallet_id", command.toWalletId())
            .data(serializeEvent(transfer))
            .build(),
        // ... other events
    );
    
    AppendCondition condition = new AppendConditionBuilder(decisionModel, projection.cursor())
        .build();
    
    // 4. All events stored atomically with DCB consistency
    // 5. Outbox automatically publishes all these events to external systems
    return CommandResult.of(events, condition);
}
```

**Key Point**: The events in `CommandResult` (can be 1 or N events) are stored with DCB transactional guarantees, then outbox publishes all these events reliably to external systems.

## How It Works

1. **Handler** returns `CommandResult(events, condition)`
2. **CommandExecutor** calls `EventStore.appendIf()` â†’ stores events in `events` table
3. **Outbox processor** polls `events` table (`WHERE position > last_position`)
4. **Publishers** send events to external systems (Kafka, webhooks, etc.)
5. **Progress tracking** updates `outbox_topic_progress` with new position

## Configuration

```properties
# Enable outbox processing
crablet.outbox.enabled=true

# Polling interval (milliseconds)
crablet.outbox.polling-interval-ms=5000

# Leader election retry interval (milliseconds)
crablet.outbox.leader-election-retry-interval-ms=30000

# Topic routing (matches DCB event tags)
crablet.outbox.topics.wallet-events.required-tags=wallet_id
crablet.outbox.topics.wallet-events.publishers=KafkaPublisher

crablet.outbox.topics.payment-events.any-of-tags=payment_id,transfer_id
crablet.outbox.topics.payment-events.publishers=AnalyticsPublisher
```

## Leader Election

The outbox uses **PostgreSQL advisory locks** for leader election, ensuring only one instance processes each publisher at a time.

### Overview

- **Global lock strategy**: Single advisory lock for all publishers across all topics
- **One leader**: Processes all publishers across all topics
- **Automatic failover**: If leader crashes, locks are released and another instance takes over
- **No configuration needed**: Leader election is transparent
- **Position tracking**: Each (topic, publisher) pair tracks its own progress independently

For complete leader election documentation including crash detection, failover timing, and deployment recommendations, see [Leader Election Guide](../../LEADER_ELECTION.md).

### Per-Publisher Schedulers

Each (topic, publisher) pair has its own independent scheduler, providing:
- **Isolation**: One publisher failure doesn't affect others
- **Flexible polling**: Configure per-publisher polling intervals
- **Clear boundaries**: Each scheduler polls independently

### Batch Processing

The outbox processes events in batches to balance throughput and latency:
- **Default batch size**: 100 events per publisher cycle
- **Configurable**: `crablet.outbox.batch-size=N`
- **SQL LIMIT**: Each publisher fetches at most N events after its last position

**Tuning guidance:**
- **Smaller batches** (10-50): Lower latency, more frequent polling overhead
- **Default** (100): Balanced for most workloads
- **Larger batches** (500-1000): Higher throughput, but longer publish cycles

### Exponential Backoff

To reduce unnecessary polling during idle periods, the outbox uses exponential backoff:
- **Threshold**: After N consecutive empty polls, backoff activates (default: 3)
- **Multiplier**: Each empty poll doubles the delay (default: 2x)
- **Max duration**: Capped at configurable seconds (default: 60s)
- **Reset**: Any successful publish immediately resets to normal polling

**Configuration:**
```properties
crablet.outbox.backoff.enabled=true
crablet.outbox.backoff.threshold=3
crablet.outbox.backoff.multiplier=2
crablet.outbox.backoff.max-seconds=60
```

## Publishers

### Available Publishers
- `LogPublisher` - Development/testing
- `CountDownLatchPublisher` - Integration tests (test-scope only)
- `StatisticsPublisher` - Monitoring
- `GlobalStatisticsPublisher` - Always-on stats

### Custom Publishers

```java
@Component
public class KafkaPublisher implements OutboxPublisher {
    @Override
    public void publishBatch(List<StoredEvent> events) throws PublishException {
        // Publish to Kafka
    }
    
    @Override
    public String getName() {
        return "KafkaPublisher";
    }
    
    @Override
    public boolean isHealthy() {
        return kafkaTemplate.isHealthy();
    }
}
```

## Management

### REST API
```bash
# Pause/resume publishers
curl -X POST http://localhost:8080/api/outbox/publishers/KafkaPublisher/pause
curl -X POST http://localhost:8080/api/outbox/publishers/KafkaPublisher/resume

# Check publisher status
curl http://localhost:8080/api/outbox/publishers/KafkaPublisher
curl http://localhost:8080/api/outbox/publishers/lag
```

### SQL Management
```sql
-- Pause publisher
UPDATE outbox_topic_progress 
SET status = 'PAUSED' 
WHERE publisher = 'KafkaPublisher';

-- Reset failed publisher
UPDATE outbox_topic_progress 
SET status = 'ACTIVE', error_count = 0, last_error = NULL 
WHERE publisher = 'KafkaPublisher';
```

## Guarantees

### At-Least-Once Delivery

**The outbox provides At-Least-Once delivery semantics, not Exactly-Once.**

Events may be published multiple times in the following scenarios:

1. **Leader failover during publishing**: Leader crashes mid-batch, backup leader starts from last committed position
2. **Publisher failure with retry**: Publisher throws exception, position not updated, next cycle retries
3. **Transactional boundary**: Events written to events table (COMMIT), publisher attempted but network failure

**Consumer requirements:**
- âœ… **Must be idempotent:** Handle duplicate events gracefully
- âœ… **Must track processed events:** Use event position/ID for deduplication
- âœ… **Must handle out-of-order scenarios:** Events may arrive out of sequence

**Implementation note:** The outbox updates `last_position` only after successful publish. If publishing fails, the same events will be retried on the next cycle until successful.

### Other Guarantees

- **Transactional Consistency**: Events published atomically with DCB operations
- **Global Ordering**: Events published in exact position order within each publisher
- **Independent Publishers**: Each publisher tracks its own progress per topic
- **Automatic Failover**: Publishing continues seamlessly if leader crashes

## When to Use

âœ… **Use when you need external event publishing:**
- Event-driven microservices
- Analytics and reporting
- Integration with external systems
- CQRS read model updates

âŒ **Don't use for:**
- Internal-only event sourcing (DCB alone is sufficient)
- High-frequency, low-latency events (polling adds latency)
- Exactly-once delivery requirements (provides at-least-once only)
- Time-critical events requiring guaranteed delivery (use synchronous publishing instead)

## Deployment Architecture

### Recommended Deployment

**Single Instance (1 replica):**
- Works fine in Kubernetes (auto-restart on crash)
- Brief downtime during pod restart (typically a few seconds to a minute)
- Suitable for development, staging, or production with acceptable restart downtime

**Multi-Instance (2+ replicas) - Recommended for Production:**
- **1 primary instance** (leader): Processes all publishers
- **1+ backup instances** (followers): Ready for automatic failover
- **Purpose of backup**: Zero-downtime failover, not load sharing
- **Failover time**: 5-30 seconds (follower takes over immediately)

**Why 2+ instances for production?**

âœ… **Zero-downtime failover**: Follower takes over within 5-30 seconds  
âœ… **Reliability**: No single point of failure  
âœ… **Simplicity**: No complex quorum or coordination needed  
âœ… **Resource efficiency**: Backup instances use minimal resources when idle

**Trade-offs:**

| Aspect | 1 Instance | 2 Instances | 3+ Instances |
|--------|------------|-------------|--------------|
| **Failover downtime** | âš ï¸ Brief (pod restart) | âœ… Zero (5-30s) | âœ… Zero (5-30s) |
| **Complexity** | âœ… Simplest | âœ… Simple | âš ï¸ Unnecessarily complex |
| **Resource usage** | âœ… Most efficient | âœ… Efficient | âš ï¸ Wasted resources |
| **Cost** | âœ… Lowest | âœ… Optimal | âš ï¸ Higher (unused instances) |

### Scaling Limits

**Optimized for:** 1-50 topic/publisher pairs

**Within this range:**
- âœ… Per-pair schedulers efficient (~50 threads)
- âœ… Global leader lock sufficient
- âœ… Database connection pool comfortable
- âœ… Monitoring queries fast

**Beyond 50 pairs:**
- âš ï¸ Thread pool saturation risk
- âš ï¸ Connection pool pressure
- âš ï¸ Architectural changes needed:
  - Batch status checking
  - Increased thread pool size
  - Per-pair leader locks for horizontal scaling
  - Partitioning outbox_topic_progress table

**Key constraints:**
1. **Global lock**: One leader processes ALL pairs (no horizontal scaling)
2. **Thread pool**: One thread per pair (consider thread limits)
3. **Database**: Sequential monitoring queries (consider query complexity)

### Architecture Diagram

**High Availability: Two Instances (Recommended)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application   â”‚â”€â”€â”€â–¶â”‚   Event Store    â”‚â”€â”€â”€â–¶â”‚  Outbox Topics  â”‚
â”‚   (DCB Commands)â”‚    â”‚  (events table)  â”‚    â”‚ (centralized)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                        â”‚
                              â–¼                        â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   State Queries  â”‚    â”‚ External Systemsâ”‚
                     â”‚  (Projections)   â”‚    â”‚ Kafka + Webhooksâ”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ + Analytics     â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Instance A (LEADER)         â”‚         â”‚  Instance B (FOLLOWER)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Outbox Processor    â”‚â”€â”€â”€â”€â–¶â–¶ Externalâ”‚  â”‚ Outbox Processor    â”‚     â”‚
â”‚  â”‚ Status: Active      â”‚     â”‚  Systemsâ”‚  â”‚ Status: Standby     â”‚     â”‚
â”‚  â”‚ Lock: Held âœ“        â”‚     â”‚         â”‚  â”‚ Lock: Waiting       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚             â†“                â”‚         â”‚             â†“                â”‚
â”‚       Global Lock            â”‚         â”‚       Monitors Lock          â”‚
â”‚        (PostgreSQL)          â”‚         â”‚       (PostgreSQL)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“                                      â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚      PostgreSQL (advisory locks)             â”‚
       â”‚  - Leader election                          â”‚
       â”‚  - Automatic failover                       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Failure scenario:** Instance A crashes â†’ PostgreSQL releases lock â†’ Instance B detects and takes over within 5-30 seconds.

For complete details on crash detection, failover mechanism, and deployment patterns, see [Leader Election Guide](../../LEADER_ELECTION.md).

## Performance

- **Polling Interval**: Configurable per-publisher (default: 1 second)
- **Batch Size**: 100 events per cycle (configurable via `crablet.outbox.batch-size`)
- **Isolation**: READ COMMITTED (sufficient due to DCB advisory locks)
- **Leader Processing**: One leader handles all publishers across all topics
- **Scalability**: Supports single instance or two instances with automatic failover

## Troubleshooting

### High Publisher Lag

**Symptoms:** Events not publishing, `outbox_lag` metric increasing

**Causes:**
- Leader instance down or unhealthy
- Publisher paused or in FAILED state
- Database connectivity issues
- External system (Kafka, webhooks) unavailable

**Resolution:**
```sql
-- Check publisher status
SELECT topic, publisher, status, last_position, error_count, last_error
FROM outbox_topic_progress;

-- Resume paused publisher
UPDATE outbox_topic_progress 
SET status = 'ACTIVE' 
WHERE publisher = 'KafkaPublisher';

-- Reset failed publisher
UPDATE outbox_topic_progress 
SET status = 'ACTIVE', error_count = 0, last_error = NULL 
WHERE publisher = 'KafkaPublisher';
```

### Frequent Leader Changes

**Symptoms:** `outbox_is_leader` metric changing frequently

**Causes:**
- Network instability between instances and database
- Database connection pool exhaustion
- Instance resource constraints (CPU, memory)

**Resolution:**
- Monitor instance health metrics
- Check network latency to database
- Increase connection pool size if needed
- Verify instance resources (CPU < 80%, memory sufficient)

### Events Published Multiple Times

**Symptoms:** Duplicate events in external systems

**Expected behavior:** At-least-once delivery semantics

**Resolution:**
- This is normal behavior (see Guarantees section)
- Ensure consumers are idempotent
- Use event position/ID for deduplication

### No Events Being Published

**Symptoms:** `outbox_events_published_total` not increasing, lag growing

**Causes:**
- All instances are followers (no leader)
- Outbox disabled in configuration
- No publishers configured for topics
- All publishers paused or failed

**Resolution:**
```bash
# Check if any instance is leader
curl http://localhost:8080/actuator/metrics/outbox.is.leader

# Check configuration
curl http://localhost:8080/actuator/env | grep outbox.enabled

# Check publishers
curl http://localhost:8080/actuator/outbox/publishers
```

## See Also

- [Leader Election Guide](../../LEADER_ELECTION.md) - Complete leader election documentation
- [EventStore README](../crablet-eventstore/README.md) - DCB event sourcing library
- [Command README](../crablet-command/README.md) - Command framework
